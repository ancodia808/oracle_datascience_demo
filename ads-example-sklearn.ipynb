{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e51904-da7d-46dc-9aa9-6737a7535145",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b84930-3bc5-4612-bd56-3029ddec0c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-21 22:24:46,939] [ads.common] In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n",
      "Start loading model.joblib from model directory /tmp/tmp4ha6qdw3 ...                                                                                                                                    ?, ?it/s]\n",
      "Model is successfully loaded.\n",
      "Start loading model.joblib from model directory /tmp/tmp4ha6qdw3 ...\n",
      "Model is successfully loaded.\n",
      "['output_schema.json', 'score.py', 'runtime.yaml', 'model.joblib', '.model-ignore', 'input_schema.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-21 22:25:01,797] [ads.model.datascience_model] the JSON object must be str, bytes or bytearray, not Schema\n",
      "[2025-10-21 22:25:01,802] [ads.model.datascience_model] the JSON object must be str, bytes or bytearray, not Schema\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "import ads\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "ads.set_auth(auth=\"resource_principal\")\n",
    "\n",
    "# Load dataset and Prepare train and test split\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Train a LogisticRegression model\n",
    "sklearn_estimator = LogisticRegression()\n",
    "sklearn_estimator.fit(X_train, y_train)\n",
    "\n",
    "# Instantiate ads.model.framework.sklearn_model.SklearnModel using the sklearn LogisticRegression model\n",
    "sklearn_model = SklearnModel(\n",
    "    estimator=sklearn_estimator, artifact_dir=tempfile.mkdtemp()\n",
    ")\n",
    "\n",
    "# Autogenerate score.py, serialized model, runtime.yaml, input_schema.json and output_schema.json\n",
    "sklearn_model.prepare(\n",
    "    inference_conda_env=\"dbexp_p38_cpu_v1\",\n",
    "    X_sample=X_train,\n",
    "    y_sample=y_train,\n",
    ")\n",
    "\n",
    "# Verify generated artifacts\n",
    "sklearn_model.verify(X_test)\n",
    "\n",
    "# Register scikit-learn model\n",
    "model_id = sklearn_model.save(display_name=\"Eric Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82e088-0b98-4db1-8c57-61345aaa7ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:automlx251_p311_cpu_x86_64_v2]",
   "language": "python",
   "name": "conda-env-automlx251_p311_cpu_x86_64_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
